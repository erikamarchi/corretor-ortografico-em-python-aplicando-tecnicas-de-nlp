{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corretor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjui4BHq5CCA7KJi533o7u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erikamarchi/corretor-ortografico-em-python-aplicando-tecnicas-de-nlp/blob/main/Corretor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SFS4y1Lx2L1"
      },
      "source": [
        "#Lê arquivo artigos Alura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gReRgYAxThv",
        "outputId": "cfbdc73e-0d8d-498b-9810-6aa98c138625"
      },
      "source": [
        "with open(\"artigos.txt\", \"r\") as f:\n",
        "    artigos = f.read()\n",
        "\n",
        "print(artigos[:500])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
            "\n",
            "java \n",
            "\n",
            "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzKdqMzvy9Qf"
      },
      "source": [
        "#Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g29kQOd9y4-P"
      },
      "source": [
        "texto_exemplo = \"Olá, tudo bem?\"\n",
        "palavras_separadas = texto_exemplo.split()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMeVu54_y7WU",
        "outputId": "f87f4a4b-1662-4568-b424-d657fe241168"
      },
      "source": [
        "print(palavras_separadas)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Olá,', 'tudo', 'bem?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obRH3giqzCFF",
        "outputId": "71466180-1c6f-4131-fb20-a3b2e7faeca4"
      },
      "source": [
        "print(len(palavras_separadas))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnMC_AsszDAX"
      },
      "source": [
        "texto_exemplo = \"Olá, tudo bem?\"\n",
        "tokens = texto_exemplo.split()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPMnr4pHzHEv",
        "outputId": "0df4bf6f-17ed-41b1-92cf-ef55c753c5e6"
      },
      "source": [
        "print(len(tokens))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzQ-j3MYzJAQ",
        "outputId": "7cadb2f2-a2a1-4d06-aaf7-9a489ddd4ca4"
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Olá,', 'tudo', 'bem?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tIhjR3G5VPH"
      },
      "source": [
        "#Redefinindo a tokenização - NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug6K-Jib50jI",
        "outputId": "3cff1f48-a45e-4608-f9a4-e2dfad6c9562"
      },
      "source": [
        "import nltk \n",
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8cLvpBw5e5G"
      },
      "source": [
        "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaisM-sn6IlC",
        "outputId": "536c13c0-ab6a-448a-b5cf-331fedee20d8"
      },
      "source": [
        "print(palavras_separadas)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Olá', ',', 'tudo', 'bem', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI4AnN9E7UJx"
      },
      "source": [
        "#Separa palavras de tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0I9ai6q7XZ1"
      },
      "source": [
        "def separa_plavras(lista_tokens):\n",
        "    lista_palavras = []\n",
        "    for token in lista_tokens:\n",
        "        if token.isalpha():\n",
        "            lista_palavras.append(token)\n",
        "    return lista_palavras"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxJfmqA37g9t",
        "outputId": "a9d582d9-ccc0-44cc-a953-4ac8a7eb6ea8"
      },
      "source": [
        "separa_plavras(palavras_separadas)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Olá', 'tudo', 'bem']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq25Vb888sbM",
        "outputId": "6fb9ffd2-70c9-4ab5-c7e4-9e274e48cbe9"
      },
      "source": [
        "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
        "lista_palavras = separa_palavras(lista_tokens)\n",
        "print(f\"O número de palavras é {len(lista_palavras)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número de palavras é 393914\n"
          ]
        }
      ]
    }
  ]
}